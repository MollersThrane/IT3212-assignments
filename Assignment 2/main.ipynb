{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and crop images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided by ChatGPT\n",
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "\n",
    "def download_image(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return Image.open(BytesIO(response.content))\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def crop_and_save_image(image, bbox, save_path):\n",
    "    width, height = image.size\n",
    "    left = bbox[0] * width\n",
    "    top = bbox[2] * height\n",
    "    right = bbox[1] * width\n",
    "    bottom = bbox[3] * height\n",
    "    \n",
    "    cropped_image = image.crop((left, top, right, bottom))\n",
    "    cropped_image.save(save_path)\n",
    "\n",
    "def process_csv(file_path, output_dir):\n",
    "    # Read the first 10 lines of the CSV file\n",
    "    df = pd.read_csv(file_path, header=None, nrows=10)\n",
    "    \n",
    "    # Iterate through each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        for i in range(0, len(row) - 5, 5):\n",
    "            url = row[i]\n",
    "            # Ensure the value is a string before checking if it is a valid URL\n",
    "            if not isinstance(url, str) or not url.startswith(\"http\"): \n",
    "                print(f\"Skipping invalid URL: {url}\")\n",
    "                continue\n",
    "            \n",
    "            bbox = [row[i+1], row[i+2], row[i+3], row[i+4]]\n",
    "            \n",
    "            # Download the image\n",
    "            image = download_image(url)\n",
    "            if image is None:\n",
    "                continue\n",
    "            \n",
    "            # Create output directory if it doesn't exist\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            # Define save path for cropped image\n",
    "            save_path = os.path.join(output_dir, f\"cropped_face_{index}_{i//5}.jpg\")\n",
    "            \n",
    "            # Crop and save the image\n",
    "            crop_and_save_image(image, bbox, save_path)\n",
    "            print(f\"Saved cropped face to {save_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to your CSV file\n",
    "    csv_file_path = \"./FEC_dataset/faceexp-comparison-data-train-public.csv\"\n",
    "    # Directory to save cropped face images\n",
    "    output_directory = \"cropped_faces\"\n",
    "    \n",
    "    process_csv(csv_file_path, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Grayscale image and 2D fourier transform it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import PIL\n",
    "import PIL.ImageOps\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def transform_and_plot_image(path: str):\n",
    "    img = Image.open(path)\n",
    "    grayscale = PIL.ImageOps.grayscale(img)\n",
    "    # grayscale.show()\n",
    "    fourier_transformed = np.fft.fft2(grayscale)\n",
    "    fourier_transformed_shifted = np.fft.fftshift(fourier_transformed)\n",
    "    magnitude_spectrum = 20 * np.log(np.abs(fourier_transformed_shifted))\n",
    "    \n",
    "    plt.subplot(121), plt.imshow(img, cmap='gray')\n",
    "    plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(122), plt.imshow(magnitude_spectrum, cmap='gray')\n",
    "    plt.title('Frequency Spectrum'), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "    return grayscale, fourier_transformed_shifted\n",
    "\n",
    "grayscale_1, fourier_transformed_1 = transform_and_plot_image(\"./cropped_faces/cropped_face_6_1.jpg\")\n",
    "grayscale_2, fourier_transformed_2 = transform_and_plot_image(\"./cropped_faces/cropped_face_9_1.jpg\")\n",
    "grayscale_3, fourier_transformed_3 = transform_and_plot_image(\"./cropped_faces/cropped_face_3_1.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low pass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def apply_low_pass_filter_and_plot(grayscale, fourier_transformed, scaling_factor=0.1):\n",
    "    # Convert grayscale image to numpy array\n",
    "    img_np = np.array(grayscale)\n",
    "    \n",
    "    # Use the provided Fourier transformed image\n",
    "    dft_shifted = fourier_transformed\n",
    "    \n",
    "    # Get image dimensions\n",
    "    rows, cols = img_np.shape\n",
    "    crow, ccol = rows // 2, cols // 2  # Center of the image\n",
    "    \n",
    "    # Calculate sigma for Gaussian based on image size and scaling factor\n",
    "    sigma = min(rows, cols) * scaling_factor\n",
    "    \n",
    "    # Create a Gaussian low-pass filter (mask)\n",
    "    x = np.linspace(-ccol, ccol, cols)\n",
    "    y = np.linspace(-crow, crow, rows)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    \n",
    "    # Gaussian function\n",
    "    gaussian_mask = np.exp(-(x**2 + y**2) / (2 * sigma**2))\n",
    "    \n",
    "    # Apply the Gaussian mask (low-pass filter)\n",
    "    dft_shifted_filtered = dft_shifted * gaussian_mask\n",
    "    \n",
    "    # Inverse DFT to get the filtered image\n",
    "    dft_inverse = np.fft.ifftshift(dft_shifted_filtered)  # Shift back the zero frequency\n",
    "    img_filtered = np.fft.ifft2(dft_inverse)\n",
    "    img_filtered = np.abs(img_filtered)\n",
    "    \n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    \n",
    "    # Original Image\n",
    "    plt.subplot(141), plt.imshow(grayscale, cmap='gray')\n",
    "    plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "    # Frequency Spectrum (Magnitude) - Original\n",
    "    magnitude_spectrum = 20 * np.log(np.abs(dft_shifted))\n",
    "    plt.subplot(142), plt.imshow(magnitude_spectrum, cmap='gray')\n",
    "    plt.title('Original Frequency Spectrum'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "    # Frequency Spectrum (Magnitude) - After Low Pass Filter\n",
    "    filtered_magnitude_spectrum = 20 * np.log(np.abs(dft_shifted_filtered) + 1)  # Add 1 to avoid log(0)\n",
    "    plt.subplot(143), plt.imshow(filtered_magnitude_spectrum, cmap='gray')\n",
    "    plt.title('Filtered Frequency Spectrum'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "    # Filtered Image\n",
    "    plt.subplot(144), plt.imshow(img_filtered, cmap='gray')\n",
    "    plt.title(f'Filtered Image (Sigma={sigma:.2f})'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Apply the function to an image\n",
    "apply_low_pass_filter_and_plot(grayscale_1, fourier_transformed_1, 0.10)\n",
    "apply_low_pass_filter_and_plot(grayscale_2, fourier_transformed_2, 0.10)\n",
    "apply_low_pass_filter_and_plot(grayscale_3, fourier_transformed_3, 0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17466, 17466)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (18923,) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 77\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;66;03m# return projected_images, components\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \n\u001b[0;32m     74\u001b[0m \n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Define the path to the folder containing images\u001b[39;00m\n\u001b[0;32m     76\u001b[0m image_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./cropped_faces\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 77\u001b[0m \u001b[43mprocess_and_pca_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 62\u001b[0m, in \u001b[0;36mprocess_and_pca_images\u001b[1;34m(image_folder, k)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     61\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, i\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 62\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgray\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOriginal Image\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     64\u001b[0m     plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Tobia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\pyplot.py:3343\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   3322\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[0;32m   3323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[0;32m   3324\u001b[0m     X: ArrayLike \u001b[38;5;241m|\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3341\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3342\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AxesImage:\n\u001b[1;32m-> 3343\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3347\u001b[0m \u001b[43m        \u001b[49m\u001b[43maspect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maspect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3348\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3349\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3352\u001b[0m \u001b[43m        \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3354\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilternorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilterrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3358\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3359\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3360\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3361\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3362\u001b[0m     sci(__ret)\n\u001b[0;32m   3363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32mc:\\Users\\Tobia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\__init__.py:1478\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1475\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1478\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1480\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1481\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1482\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\Users\\Tobia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:5756\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5754\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m-> 5756\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5757\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[0;32m   5758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5759\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tobia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\image.py:723\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[0;32m    722\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[1;32m--> 723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tobia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\image.py:693\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[1;34m(A)\u001b[0m\n\u001b[0;32m    691\u001b[0m     A \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[1;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[0;32m    699\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid shape (18923,) for image data"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARAAAAEDCAYAAAD9SFsgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAWgUlEQVR4nO3cf0xV9/3H8Rdcvedq6r3SMS4/di3BztpWhRXk7mqNcbkriYaOP5YybYARf8yWGcvNVkGUW2vLZc4akoolMq39ow46o6YpBNfeSRorCxlwEztRY9HCmt0rrPNehi1X7v18/2i9LQKW85HLvXz7eiT3Dz/9nHveaO8z5/4iRgghQEQkITbSAxDRzMWAEJE0BoSIpDEgRCSNASEiaQwIEUljQIhIGgNCRNIYECKSxoAQkTTVAfnwww+Rm5uL5ORkxMTE4PTp0995TGtrK5544gkoioKHH34Yx44dkxiViKKN6oAMDQ0hPT0dtbW1k9p/7do1rFu3DmvWrIHL5cILL7yATZs24cyZM6qHJaLoEnM/X6aLiYnBqVOnkJeXN+GeHTt2oKmpCR9//HFo7Ve/+hVu3ryJlpYW2VMTURSYFe4TtLW1wWq1jlrLycnBCy+8MOExw8PDGB4eDv05GAzi888/xw9+8APExMSEa1Si/9eEEBgcHERycjJiY6fm5c+wB8TtdsNoNI5aMxqN8Pl8+OKLLzBnzpwxxzgcDuzZsyfcoxF9L/X19eFHP/rRlNxX2AMio7y8HDabLfRnr9eLBQsWoK+vD3q9PoKTEc1cPp8PJpMJ8+bNm7L7DHtAEhMT4fF4Rq15PB7o9fpxrz4AQFEUKIoyZl2v1zMgRPdpKl8GCPvnQCwWC5xO56i1999/HxaLJdynJqIwUx2Q//3vf3C5XHC5XAC+epvW5XKht7cXwFdPPwoLC0P7t27dip6eHrz44ou4dOkSDh06hHfeeQelpaVT8xMQUeQIlc6ePSsAjLkVFRUJIYQoKioSq1evHnNMRkaG0Gq1Ii0tTbz55puqzun1egUA4fV61Y5LRF8Lx+Povj4HMl18Ph8MBgO8Xi9fAyGSFI7HEb8LQ0TSGBAiksaAEJE0BoSIpDEgRCSNASEiaQwIEUljQIhIGgNCRNIYECKSxoAQkTQGhIikMSBEJI0BISJpDAgRSWNAiEgaA0JE0hgQIpLGgBCRNAaEiKQxIEQkjQEhImkMCBFJY0CISBoDQkTSGBAiksaAEJE0BoSIpDEgRCSNASEiaQwIEUmTCkhtbS1SU1Oh0+lgNpvR3t5+z/01NTV45JFHMGfOHJhMJpSWluLLL7+UGpiIoofqgDQ2NsJms8Fut6OzsxPp6enIycnBjRs3xt1//PhxlJWVwW63o7u7G0eOHEFjYyN27tx538MTUWSpDsiBAwewefNmFBcX47HHHkNdXR3mzp2Lo0ePjrv//PnzWLlyJTZs2IDU1FQ89dRTWL9+/XdetRBR9FMVEL/fj46ODlit1m/uIDYWVqsVbW1t4x6zYsUKdHR0hILR09OD5uZmrF27dsLzDA8Pw+fzjboRUfSZpWbzwMAAAoEAjEbjqHWj0YhLly6Ne8yGDRswMDCAJ598EkIIjIyMYOvWrfd8CuNwOLBnzx41oxFRBIT9XZjW1lZUVVXh0KFD6OzsxMmTJ9HU1IS9e/dOeEx5eTm8Xm/o1tfXF+4xiUiCqiuQ+Ph4aDQaeDyeUesejweJiYnjHrN7924UFBRg06ZNAIClS5diaGgIW7ZsQUVFBWJjxzZMURQoiqJmNCKKAFVXIFqtFpmZmXA6naG1YDAIp9MJi8Uy7jG3bt0aEwmNRgMAEEKonZeIooiqKxAAsNlsKCoqQlZWFrKzs1FTU4OhoSEUFxcDAAoLC5GSkgKHwwEAyM3NxYEDB/CTn/wEZrMZV69exe7du5GbmxsKCRHNTKoDkp+fj/7+flRWVsLtdiMjIwMtLS2hF1Z7e3tHXXHs2rULMTEx2LVrFz777DP88Ic/RG5uLl599dWp+ymIKCJixAx4HuHz+WAwGOD1eqHX6yM9DtGMFI7HEb8LQ0TSGBAiksaAEJE0BoSIpDEgRCSNASEiaQwIEUljQIhIGgNCRNIYECKSxoAQkTQGhIikMSBEJI0BISJpDAgRSWNAiEgaA0JE0hgQIpLGgBCRNAaEiKQxIEQkjQEhImkMCBFJY0CISBoDQkTSGBAiksaAEJE0BoSIpDEgRCSNASEiaQwIEUmTCkhtbS1SU1Oh0+lgNpvR3t5+z/03b95ESUkJkpKSoCgKFi1ahObmZqmBiSh6zFJ7QGNjI2w2G+rq6mA2m1FTU4OcnBxcvnwZCQkJY/b7/X78/Oc/R0JCAk6cOIGUlBR8+umnmD9//lTMT0QRFCOEEGoOMJvNWL58OQ4ePAgACAaDMJlM2LZtG8rKysbsr6urwx//+EdcunQJs2fPlhrS5/PBYDDA6/VCr9dL3QfR9104HkeqnsL4/X50dHTAarV+cwexsbBarWhraxv3mHfffRcWiwUlJSUwGo1YsmQJqqqqEAgEJjzP8PAwfD7fqBsRRR9VARkYGEAgEIDRaBy1bjQa4Xa7xz2mp6cHJ06cQCAQQHNzM3bv3o3XXnsNr7zyyoTncTgcMBgMoZvJZFIzJhFNk7C/CxMMBpGQkIDDhw8jMzMT+fn5qKioQF1d3YTHlJeXw+v1hm59fX3hHpOIJKh6ETU+Ph4ajQYej2fUusfjQWJi4rjHJCUlYfbs2dBoNKG1Rx99FG63G36/H1qtdswxiqJAURQ1oxFRBKi6AtFqtcjMzITT6QytBYNBOJ1OWCyWcY9ZuXIlrl69imAwGFq7cuUKkpKSxo0HEc0cqp/C2Gw21NfX46233kJ3dzeee+45DA0Nobi4GABQWFiI8vLy0P7nnnsOn3/+ObZv344rV66gqakJVVVVKCkpmbqfgogiQvXnQPLz89Hf34/Kykq43W5kZGSgpaUl9MJqb28vYmO/6ZLJZMKZM2dQWlqKZcuWISUlBdu3b8eOHTum7qcgoohQ/TmQSODnQIjuX8Q/B0JE9G0MCBFJY0CISBoDQkTSGBAiksaAEJE0BoSIpDEgRCSNASEiaQwIEUljQIhIGgNCRNIYECKSxoAQkTQGhIikMSBEJI0BISJpDAgRSWNAiEgaA0JE0hgQIpLGgBCRNAaEiKQxIEQkjQEhImkMCBFJY0CISBoDQkTSGBAiksaAEJE0BoSIpEkFpLa2FqmpqdDpdDCbzWhvb5/UcQ0NDYiJiUFeXp7MaYkoyqgOSGNjI2w2G+x2Ozo7O5Geno6cnBzcuHHjnsddv34dv/vd77Bq1SrpYYkouqgOyIEDB7B582YUFxfjscceQ11dHebOnYujR49OeEwgEMCzzz6LPXv2IC0t7b4GJqLooSogfr8fHR0dsFqt39xBbCysViva2tomPO7ll19GQkICNm7cOKnzDA8Pw+fzjboRUfRRFZCBgQEEAgEYjcZR60ajEW63e9xjzp07hyNHjqC+vn7S53E4HDAYDKGbyWRSMyYRTZOwvgszODiIgoIC1NfXIz4+ftLHlZeXw+v1hm59fX1hnJKIZM1Sszk+Ph4ajQYej2fUusfjQWJi4pj9n3zyCa5fv47c3NzQWjAY/OrEs2bh8uXLWLhw4ZjjFEWBoihqRiOiCFB1BaLVapGZmQmn0xlaCwaDcDqdsFgsY/YvXrwYFy5cgMvlCt2efvpprFmzBi6Xi09NiGY4VVcgAGCz2VBUVISsrCxkZ2ejpqYGQ0NDKC4uBgAUFhYiJSUFDocDOp0OS5YsGXX8/PnzAWDMOhHNPKoDkp+fj/7+flRWVsLtdiMjIwMtLS2hF1Z7e3sRG8sPuBJ9H8QIIUSkh/guPp8PBoMBXq8Xer0+0uMQzUjheBzxUoGIpDEgRCSNASEiaQwIEUljQIhIGgNCRNIYECKSxoAQkTQGhIikMSBEJI0BISJpDAgRSWNAiEgaA0JE0hgQIpLGgBCRNAaEiKQxIEQkjQEhImkMCBFJY0CISBoDQkTSGBAiksaAEJE0BoSIpDEgRCSNASEiaQwIEUljQIhIGgNCRNIYECKSJhWQ2tpapKamQqfTwWw2o729fcK99fX1WLVqFeLi4hAXFwer1XrP/UQ0c6gOSGNjI2w2G+x2Ozo7O5Geno6cnBzcuHFj3P2tra1Yv349zp49i7a2NphMJjz11FP47LPP7nt4IoqsGCGEUHOA2WzG8uXLcfDgQQBAMBiEyWTCtm3bUFZW9p3HBwIBxMXF4eDBgygsLJzUOX0+HwwGA7xeL/R6vZpxiehr4XgcqboC8fv96OjogNVq/eYOYmNhtVrR1tY2qfu4desWbt++jQcffHDCPcPDw/D5fKNuRBR9VAVkYGAAgUAARqNx1LrRaITb7Z7UfezYsQPJycmjInQ3h8MBg8EQuplMJjVjEtE0mdZ3Yaqrq9HQ0IBTp05Bp9NNuK+8vBxerzd06+vrm8YpiWiyZqnZHB8fD41GA4/HM2rd4/EgMTHxnsfu378f1dXV+OCDD7Bs2bJ77lUUBYqiqBmNiCJA1RWIVqtFZmYmnE5naC0YDMLpdMJisUx43L59+7B37160tLQgKytLfloiiiqqrkAAwGazoaioCFlZWcjOzkZNTQ2GhoZQXFwMACgsLERKSgocDgcA4A9/+AMqKytx/PhxpKamhl4reeCBB/DAAw9M4Y9CRNNNdUDy8/PR39+PyspKuN1uZGRkoKWlJfTCam9vL2Jjv7mweeONN+D3+/HLX/5y1P3Y7Xa89NJL9zc9EUWU6s+BRAI/B0J0/yL+ORAiom9jQIhIGgNCRNIYECKSxoAQkTQGhIikMSBEJI0BISJpDAgRSWNAiEgaA0JE0hgQIpLGgBCRNAaEiKQxIEQkjQEhImkMCBFJY0CISBoDQkTSGBAiksaAEJE0BoSIpDEgRCSNASEiaQwIEUljQIhIGgNCRNIYECKSxoAQkTQGhIikMSBEJE0qILW1tUhNTYVOp4PZbEZ7e/s99//lL3/B4sWLodPpsHTpUjQ3N0sNS0TRRXVAGhsbYbPZYLfb0dnZifT0dOTk5ODGjRvj7j9//jzWr1+PjRs3oqurC3l5ecjLy8PHH39838MTUWTFCCGEmgPMZjOWL1+OgwcPAgCCwSBMJhO2bduGsrKyMfvz8/MxNDSE9957L7T205/+FBkZGairq5vUOX0+HwwGA7xeL/R6vZpxiehr4XgczVKz2e/3o6OjA+Xl5aG12NhYWK1WtLW1jXtMW1sbbDbbqLWcnBycPn16wvMMDw9jeHg49Gev1wvgq78AIpJz5/Gj8prhnlQFZGBgAIFAAEajcdS60WjEpUuXxj3G7XaPu9/tdk94HofDgT179oxZN5lMasYlonH85z//gcFgmJL7UhWQ6VJeXj7qquXmzZt46KGH0NvbO2U/eDj4fD6YTCb09fVF9VMtzjm1ZsqcXq8XCxYswIMPPjhl96kqIPHx8dBoNPB4PKPWPR4PEhMTxz0mMTFR1X4AUBQFiqKMWTcYDFH9D3SHXq/nnFOIc06t2Nip+/SGqnvSarXIzMyE0+kMrQWDQTidTlgslnGPsVgso/YDwPvvvz/hfiKaOVQ/hbHZbCgqKkJWVhays7NRU1ODoaEhFBcXAwAKCwuRkpICh8MBANi+fTtWr16N1157DevWrUNDQwP+8Y9/4PDhw1P7kxDRtFMdkPz8fPT396OyshJutxsZGRloaWkJvVDa29s76hJpxYoVOH78OHbt2oWdO3fixz/+MU6fPo0lS5ZM+pyKosBut4/7tCaacM6pxTmnVjjmVP05ECKiO/hdGCKSxoAQkTQGhIikMSBEJC1qAjJTfkWAmjnr6+uxatUqxMXFIS4uDlar9Tt/rkjM+W0NDQ2IiYlBXl5eeAf8mto5b968iZKSEiQlJUFRFCxatGha/u3VzllTU4NHHnkEc+bMgclkQmlpKb788suwzffhhx8iNzcXycnJiImJued3ze5obW3FE088AUVR8PDDD+PYsWPqTyyiQENDg9BqteLo0aPin//8p9i8ebOYP3++8Hg84+7/6KOPhEajEfv27RMXL14Uu3btErNnzxYXLlyIqjk3bNggamtrRVdXl+ju7ha//vWvhcFgEP/617+ias47rl27JlJSUsSqVavEL37xi7DOKDPn8PCwyMrKEmvXrhXnzp0T165dE62trcLlckXVnG+//bZQFEW8/fbb4tq1a+LMmTMiKSlJlJaWhm3G5uZmUVFRIU6ePCkAiFOnTt1zf09Pj5g7d66w2Wzi4sWL4vXXXxcajUa0tLSoOm9UBCQ7O1uUlJSE/hwIBERycrJwOBzj7n/mmWfEunXrRq2ZzWbxm9/8JqrmvNvIyIiYN2+eeOutt8I1ohBCbs6RkRGxYsUK8ac//UkUFRVNS0DUzvnGG2+ItLQ04ff7wz7bt6mds6SkRPzsZz8btWaz2cTKlSvDOucdkwnIiy++KB5//PFRa/n5+SInJ0fVuSL+FObOrwiwWq2htcn8ioBv7we++hUBE+2P1Jx3u3XrFm7fvj2lX2a6m+ycL7/8MhISErBx48awzfZtMnO+++67sFgsKCkpgdFoxJIlS1BVVYVAIBBVc65YsQIdHR2hpzk9PT1obm7G2rVrwzanWlP1GIr4t3Gn61cERGLOu+3YsQPJyclj/uGmksyc586dw5EjR+ByucI2191k5uzp6cHf/vY3PPvss2hubsbVq1fx/PPP4/bt27Db7VEz54YNGzAwMIAnn3wSQgiMjIxg69at2LlzZ1hmlDHRY8jn8+GLL77AnDlzJnU/Eb8C+b6orq5GQ0MDTp06BZ1OF+lxQgYHB1FQUID6+nrEx8dHepx7CgaDSEhIwOHDh5GZmYn8/HxUVFRM+jfbTZfW1lZUVVXh0KFD6OzsxMmTJ9HU1IS9e/dGerQpF/ErkOn6FQGRmPOO/fv3o7q6Gh988AGWLVsWthkB9XN+8sknuH79OnJzc0NrwWAQADBr1ixcvnwZCxcujPicAJCUlITZs2dDo9GE1h599FG43W74/X5otdqomHP37t0oKCjApk2bAABLly7F0NAQtmzZgoqKiin9Or2siR5Der1+0lcfQBRcgcyUXxEgMycA7Nu3D3v37kVLSwuysrLCNp/snIsXL8aFCxfgcrlCt6effhpr1qyBy+UK22+Bk/n7XLlyJa5evRoKHABcuXIFSUlJYYmH7Jy3bt0aE4k70RNR8tWzKXsMqXt9NzwaGhqEoiji2LFj4uLFi2LLli1i/vz5wu12CyGEKCgoEGVlZaH9H330kZg1a5bYv3+/6O7uFna7fdrexlUzZ3V1tdBqteLEiRPi3//+d+g2ODgYVXPebbrehVE7Z29vr5g3b5747W9/Ky5fvizee+89kZCQIF555ZWomtNut4t58+aJP//5z6Knp0f89a9/FQsXLhTPPPNM2GYcHBwUXV1doqurSwAQBw4cEF1dXeLTTz8VQghRVlYmCgoKQvvvvI37+9//XnR3d4va2tqZ+zauEEK8/vrrYsGCBUKr1Yrs7Gzx97//PfTfVq9eLYqKikbtf+edd8SiRYuEVqsVjz/+uGhqaoq6OR966CEBYMzNbrdH1Zx3m66ACKF+zvPnzwuz2SwURRFpaWni1VdfFSMjI1E15+3bt8VLL70kFi5cKHQ6nTCZTOL5558X//3vf8M239mzZ8f9f+3OXEVFRWL16tVjjsnIyBBarVakpaWJN998U/V5+XV+IpIW8ddAiGjmYkCISBoDQkTSGBAiksaAEJE0BoSIpDEgRCSNASEiaQwIEUljQIhIGgNCRNIYECKS9n+gJOSQoJuw7AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Open image and convert to grayscale\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    image_array = np.array(image).flatten()\n",
    "\n",
    "    # Normalize the pixel values to the range [0, 1]\n",
    "    normalized_image = (image_array - np.min(image_array)) / (np.max(image_array) - np.min(image_array))\n",
    "    return normalized_image  # Flatten into 1D array for PCA\n",
    "\n",
    "def pca(images, num_components=10):\n",
    "    # Stack the image data into a matrix (each row is an image)\n",
    "    image_matrix = np.vstack(images)\n",
    "    \n",
    "    # print(np.array(grayscale_img))\n",
    "    # print(reshaped_image)\n",
    "\n",
    "    # Compute the covariance matrix\n",
    "    covariance_matrix = np.cov(image_matrix, rowvar=False)\n",
    "\n",
    "    print(covariance_matrix.shape)\n",
    "    \n",
    "    # Perform eigendecomposition\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "    \n",
    "    # Sort the eigenvectors based on eigenvalues in descending order\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "    sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "    \n",
    "    # Select the top k eigenvectors\n",
    "    top_eigenvectors = sorted_eigenvectors[:, :num_components]\n",
    "    \n",
    "    # Project the original images onto the lower-dimensional subspace defined by the selected principal components\n",
    "    projected_data = np.dot(image_matrix, top_eigenvectors)\n",
    "\n",
    "    return projected_data, top_eigenvectors\n",
    "\n",
    "def process_and_pca_images(image_folder, k=10):\n",
    "    # Load and preprocess images\n",
    "    image_files = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith('0_0.jpg') or f.endswith('0_1.jpg')]\n",
    "    images = [preprocess_image(image_file) for image_file in image_files]\n",
    "    \n",
    "    # Find the minimum array length in the images\n",
    "    min_length = min(len(row) for row in images)\n",
    "    \n",
    "    # Truncate all rows to the minimum length\n",
    "    truncated_images = np.array([row[:min_length] for row in images])\n",
    "    \n",
    "    # Perform PCA\n",
    "    projected_images, components = pca(truncated_images, k)\n",
    "\n",
    "    # Show two of the original and their reconstructed images\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(2):\n",
    "        plt.subplot(2, 2, i*2 + 1)\n",
    "        plt.imshow(images[i], cmap='gray')\n",
    "        plt.title('Original Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        reconstructed_image = np.dot(projected_images[i], components.T)\n",
    "        plt.subplot(2, 2, i*2 + 2)\n",
    "        plt.imshow(reconstructed_image.reshape(100, 100), cmap='gray')\n",
    "        plt.title('Reconstructed Image')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    # return projected_images, components\n",
    "\n",
    "\n",
    "# Define the path to the folder containing images\n",
    "image_folder = \"./cropped_faces\"\n",
    "process_and_pca_images(image_folder, k=10)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
